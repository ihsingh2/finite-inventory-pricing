{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finite Inventory Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from algorithms import policy_iteration, q_learning, sarsa_lambda, value_iteration\n",
    "from constants import K, T, PRICES, TRACE_DECAY, GAUSSIAN_SMOOTHING_STD\n",
    "from scipy.ndimage import gaussian_filter, gaussian_filter1d\n",
    "\n",
    "plt.rcParams[\"figure.autolayout\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_policy(policy, title = '', fig = None, ax = None, sigma = 0.0):\n",
    "    \"\"\" Displays the image represented by an array. \"\"\"\n",
    "\n",
    "    policy_matrix = np.zeros((K, T))\n",
    "    for inv in range(1, K + 1):\n",
    "        for t in range(1, T + 1):\n",
    "            policy_matrix[inv - 1, t - 1] = policy[(inv, t)]\n",
    "    policy_matrix = gaussian_filter(policy_matrix, sigma=sigma)\n",
    "\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        plt.imshow(policy_matrix, cmap='viridis', aspect='auto')\n",
    "        plt.colorbar(label='Price')\n",
    "        plt.title(title)\n",
    "        plt.ylabel('Remaining Seats')\n",
    "        plt.xlabel('Days Left')\n",
    "        plt.ylim(1, K - 1)\n",
    "        plt.xlim(1, T - 1)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        im = ax.imshow(policy_matrix, cmap='viridis', aspect='auto')\n",
    "        cbar = fig.colorbar(im, ax=ax)\n",
    "        cbar.set_label('Price', fontsize=12)\n",
    "        ax.set_title(title, fontsize=14)\n",
    "        ax.set_ylabel('Remaining Seats', fontsize=12)\n",
    "        ax.set_xlabel('Days Left', fontsize=12)\n",
    "        ax.set_ylim(1, K - 1)\n",
    "        ax.set_xlim(1, T - 1)\n",
    "\n",
    "def plot_episode_rewards(metrics, title = 'Total Discounted Rewards per Episode', ax = None, label = None):\n",
    "    \"\"\" Plots the total discounted rewards per episode. \"\"\"\n",
    "\n",
    "    if label is None:\n",
    "        ax.plot(gaussian_filter1d(metrics['episode_rewards'], sigma=GAUSSIAN_SMOOTHING_STD))\n",
    "    else:\n",
    "        ax.plot(gaussian_filter1d(metrics['episode_rewards'], sigma=GAUSSIAN_SMOOTHING_STD), label=label)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_ylabel('Total Discounted Reward', fontsize=12)\n",
    "    ax.set_xlabel('Episode', fontsize=12)\n",
    "    ax.grid(linewidth=0.35)\n",
    "\n",
    "def plot_episode_regrets(metrics, title = 'Instantaneous Episodic Regret', ax = None, label = None):\n",
    "    \"\"\" Plots the instantaneous episodic regret. \"\"\"\n",
    "\n",
    "    if label is None:\n",
    "        ax.plot(gaussian_filter1d(metrics['episode_regrets'], sigma=GAUSSIAN_SMOOTHING_STD))\n",
    "    else:\n",
    "        ax.plot(gaussian_filter1d(metrics['episode_regrets'], sigma=GAUSSIAN_SMOOTHING_STD), label=label)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_ylabel('Regret', fontsize=12)\n",
    "    ax.set_xlabel('Episode', fontsize=12)\n",
    "    ax.grid(linewidth=0.35)\n",
    "\n",
    "def plot_cumulative_rewards(metrics, title = 'Cumulative Discounted Rewards over Episodes', ax = None, label = None):\n",
    "    \"\"\" Plots the cumulative discounted rewards over episode. \"\"\"\n",
    "\n",
    "    if label is None:\n",
    "        ax.plot(gaussian_filter1d(metrics['cumulative_rewards'], sigma=GAUSSIAN_SMOOTHING_STD))\n",
    "    else:\n",
    "        ax.plot(gaussian_filter1d(metrics['cumulative_rewards'], sigma=GAUSSIAN_SMOOTHING_STD), label=label)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_ylabel('Cumulative Discounted Reward', fontsize=12)\n",
    "    ax.set_xlabel('Episode', fontsize=12)\n",
    "    ax.grid(linewidth=0.35)\n",
    "\n",
    "def plot_cumulative_regrets(metrics, title = 'Cumulative Regrets over Episodes', ax = None, label = None):\n",
    "    \"\"\" Plots the cumulative regrets over episodes. \"\"\"\n",
    "\n",
    "    if label is None:\n",
    "        ax.plot(gaussian_filter1d(metrics['cumulative_regrets'], sigma=GAUSSIAN_SMOOTHING_STD))\n",
    "    else:\n",
    "        ax.plot(gaussian_filter1d(metrics['cumulative_regrets'], sigma=GAUSSIAN_SMOOTHING_STD), label=label)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_ylabel('Cumulative Regret', fontsize=12)\n",
    "    ax.set_xlabel('Episode', fontsize=12)\n",
    "    ax.grid(linewidth=0.35)\n",
    "\n",
    "def save_plot(dest_path):\n",
    "    \"\"\" Saves the plot as an image file, given the absolute path. \"\"\"\n",
    "\n",
    "    plt.savefig(dest_path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Learned Policies, Rewards and Regrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_vi, policy_vi = value_iteration()\n",
    "V_pi, policy_pi = policy_iteration()\n",
    "Q_ql, policy_ql, metrics_ql = q_learning()\n",
    "Q_sarsa, policy_sarsa, metrics_sarsa = sarsa_lambda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "plot_policy(policy_vi, 'Value/Policy Iteration', fig, axs[0])\n",
    "plot_policy(policy_ql, 'Q-Learning', fig, axs[1])\n",
    "plot_policy(policy_sarsa, 'SARSA(λ)', fig, axs[2])\n",
    "\n",
    "save_plot('../slides/figures/policy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "plot_policy(policy_vi, 'Value/Policy Iteration', fig, axs[0], 1.0)\n",
    "plot_policy(policy_ql, 'Q-Learning', fig, axs[1], 1.0)\n",
    "plot_policy(policy_sarsa, 'SARSA(λ)', fig, axs[2], 1.0)\n",
    "\n",
    "save_plot('../slides/figures/policy_smooth.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(18, 5))\n",
    "\n",
    "plot_episode_rewards(metrics_ql, ax=axs[0], label='Q-Learning')\n",
    "plot_episode_rewards(metrics_sarsa, ax=axs[0], label='SARSA(λ)')\n",
    "axs[0].legend(fontsize=12, loc='upper right')\n",
    "\n",
    "plot_cumulative_rewards(metrics_ql, ax=axs[1], label='Q-Learning')\n",
    "plot_cumulative_rewards(metrics_sarsa, ax=axs[1], label='SARSA(λ)')\n",
    "axs[1].legend(fontsize=12)\n",
    "\n",
    "save_plot('../slides/figures/reward.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(18, 5))\n",
    "\n",
    "plot_episode_regrets(metrics_ql, ax=axs[0], label='Q-Learning')\n",
    "plot_episode_regrets(metrics_sarsa, ax=axs[0], label='SARSA(λ)')\n",
    "axs[0].legend(fontsize=12)\n",
    "\n",
    "plot_cumulative_regrets(metrics_ql, ax=axs[1], label='Q-Learning')\n",
    "plot_cumulative_regrets(metrics_sarsa, ax=axs[1], label='SARSA(λ)')\n",
    "axs[1].legend(fontsize=12)\n",
    "\n",
    "save_plot('../slides/figures/regret.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Effect of Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ability to modify hyperparameters on the fly has not been added for simplicity. Changes have to be made manually with kernel restarts for them to take effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, policy_10, metrics_10 = q_learning()\n",
    "# with open('.tmp/epsilon_10.pkl', 'wb') as f:\n",
    "#     pickle.dump([policy_10, metrics_10], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, policy_20, metrics_20 = q_learning()\n",
    "# with open('.tmp/epsilon_20.pkl', 'wb') as f:\n",
    "#     pickle.dump([policy_20, metrics_20], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, policy_30, metrics_30 = q_learning()\n",
    "# with open('.tmp/epsilon_30.pkl', 'wb') as f:\n",
    "#     pickle.dump([policy_30, metrics_30], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.tmp/epsilon_10.pkl', 'rb') as f:\n",
    "    policy_10, metrics_10 = pickle.load(f)\n",
    "\n",
    "with open('.tmp/epsilon_20.pkl', 'rb') as f:\n",
    "    policy_20, metrics_20 = pickle.load(f)\n",
    "\n",
    "with open('.tmp/epsilon_30.pkl', 'rb') as f:\n",
    "    policy_30, metrics_30 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "plot_policy(policy_10, 'ε=0.1', fig, axs[0], 1.0)\n",
    "plot_policy(policy_20, 'ε=0.2', fig, axs[1], 1.0)\n",
    "plot_policy(policy_30, 'ε=0.3', fig, axs[2], 1.0)\n",
    "\n",
    "save_plot('../slides/figures/epsilon_policy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(18, 5))\n",
    "\n",
    "plot_episode_rewards(metrics_10, ax=axs[0], label='ε=0.1')\n",
    "plot_episode_rewards(metrics_20, ax=axs[0], label='ε=0.2')\n",
    "plot_episode_rewards(metrics_30, ax=axs[0], label='ε=0.3')\n",
    "axs[0].legend(fontsize=12)\n",
    "\n",
    "plot_episode_regrets(metrics_10, ax=axs[1], label='ε=0.1')\n",
    "plot_episode_regrets(metrics_20, ax=axs[1], label='ε=0.2')\n",
    "plot_episode_regrets(metrics_30, ax=axs[1], label='ε=0.3')\n",
    "axs[1].legend(fontsize=12)\n",
    "\n",
    "save_plot('../slides/figures/epsilon_metrics.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Effect of Trace Decay Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ability to modify hyperparameters on the fly has not been added for simplicity. Changes have to be made manually with kernel restarts for them to take effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, policy_100, metrics_100 = sarsa_lambda()\n",
    "# with open('.tmp/lambda_100.pkl', 'wb') as f:\n",
    "#     pickle.dump([policy_100, metrics_100], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, policy_90, metrics_90 = sarsa_lambda()\n",
    "# with open('.tmp/lambda_90.pkl', 'wb') as f:\n",
    "#     pickle.dump([policy_90, metrics_90], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, policy_80, metrics_80 = sarsa_lambda()\n",
    "# with open('.tmp/lambda_80.pkl', 'wb') as f:\n",
    "#     pickle.dump([policy_80, metrics_80], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.tmp/lambda_100.pkl', 'rb') as f:\n",
    "    policy_100, metrics_100 = pickle.load(f)\n",
    "\n",
    "with open('.tmp/lambda_90.pkl', 'rb') as f:\n",
    "    policy_90, metrics_90 = pickle.load(f)\n",
    "\n",
    "with open('.tmp/lambda_80.pkl', 'rb') as f:\n",
    "    policy_80, metrics_80 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "plot_policy(policy_80, 'λ=0.80', fig, axs[0], 1.0)\n",
    "plot_policy(policy_90, 'λ=0.90', fig, axs[1], 1.0)\n",
    "plot_policy(policy_100, 'λ=1.00', fig, axs[2], 1.0)\n",
    "\n",
    "save_plot('../slides/figures/lambda_policy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(18, 5))\n",
    "\n",
    "plot_episode_rewards(metrics_80, ax=axs[0], label='λ=0.80')\n",
    "plot_episode_rewards(metrics_90, ax=axs[0], label='λ=0.90')\n",
    "plot_episode_rewards(metrics_100, ax=axs[0], label='λ=1.00')\n",
    "axs[0].legend(fontsize=12, loc='upper left')\n",
    "\n",
    "plot_episode_regrets(metrics_80, ax=axs[1], label='λ=0.80')\n",
    "plot_episode_regrets(metrics_90, ax=axs[1], label='λ=0.90')\n",
    "plot_episode_regrets(metrics_100, ax=axs[1], label='λ=1.00')\n",
    "axs[1].legend(fontsize=12)\n",
    "\n",
    "save_plot('../slides/figures/lambda_metrics.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iiit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
